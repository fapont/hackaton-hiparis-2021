{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Notebook Team 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Install your packages below: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des requirements\n",
    "!pip install .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/building_1.pkl', 'rb') as f:\n",
    "    building_1 = pickle.load(f)\n",
    "\n",
    "with open('../data/building_2.pkl', 'rb') as f:\n",
    "    building_2 = pickle.load(f)\n",
    "    \n",
    "with open('../data/building_3.pkl', 'rb') as f:\n",
    "    building_3 = pickle.load(f)\n",
    "\n",
    "buildings = [building_1, building_2, building_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluation for Rule Based Approaches </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1) Import all used libraries and scripts here </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # Necessary to evaluate frugality\n",
    "import json # Necessary to export your results\n",
    "from grid37 import Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2) Implementation of the rules that generate control dictionaries </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_algos = Rules.Naive_algo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 3) Run of the rules on the Test environment </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rule based methods have no \"training\" as such, this means Training CPU Time will always be 0 and only\n",
    "Test CPU Time will represent frugality\n",
    "\"\"\"\n",
    "\n",
    "eval_start = time.process_time()\n",
    "\n",
    "total_building_costs = []\n",
    "\n",
    "for building in buildings:\n",
    "\n",
    "    building.reset(testing = True)\n",
    "\n",
    "    total_building_cost = naive_algos.compute(building)\n",
    "    total_building_costs.append(total_building_cost)\n",
    "\n",
    "eval_end = time.process_time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost_building_1 = total_building_costs[0]\n",
    "total_cost_building_2 = total_building_costs[1]\n",
    "total_cost_building_3 = total_building_costs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frugality = eval_end - eval_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4) Store & Export Results in JSON format </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {\n",
    "    \"building_1_performance\" : total_cost_building_1,\n",
    "    \"building_2_performance\" : total_cost_building_2,\n",
    "    \"building_3_performance\" : total_cost_building_3,\n",
    "    \"frugality\" : frugality,\n",
    "}\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = \"team37\"## Enter Team name here\n",
    "\n",
    "with open('../' + team_name + '.txt', 'w') as json_file:\n",
    "    json.dump(final_results, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluation for \"Simple\" Reinforcement Learning based approaches <h2>\n",
    "<font color='red'> <h4> Note importante: le choix de notre équipe s'est porté sur l'algorithme rule based ci-dessus, le code présenté ci-après n'est donc pas utilisé pour notre benchmark </h4> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1) Import all used libraries and scripts here </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid37 import DiscreteEnvironment, Reinforcement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2) Agent & Environment Setup before your training </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_environments = [\n",
    "    DiscreteEnvironment.Environment(env_config={'building':buildings[i]}) for i in range(3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 3) Training of the agent </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner1 = Reinforcement.QLearner(building_environments[0], \"double\")\n",
    "evol1 = learner1.train(horizon=-1, alpha=\"adaptative\", gamma=0.5, nb_episode=100, plot=True)\n",
    "\n",
    "learner2 = Reinforcement.QLearner(building_environments[1], \"double\")\n",
    "evol2 = learner2.train(horizon=-1, alpha=0.05, gamma=0.5, nb_episode=100, plot=True)\n",
    "\n",
    "learner3 = Reinforcement.QLearner(building_environments[2], \"double\")\n",
    "evol3 = learner3.train(horizon=-1, alpha=0.05, gamma=0.5, nb_episode=100, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4) Test of the agent </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not compute the frugality since this is not our best algorithm\n",
    "total_cost[0] = learner1.test(horizon=-1, env=None, testing=True, verbose=False)\n",
    "total_cost[1] = learner2.test(horizon=-1, env=None, testing=True, verbose=False)\n",
    "total_cost[2] = learner3.test(horizon=-1, env=None, testing=True, verbose=False)\n",
    "\n",
    "print(total_cost)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
